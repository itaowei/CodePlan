<html><body><pre><hr><h1>audiocraft\utils\cluster.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\data\info_audio_dataset.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>scripts\mos.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\utils\deadlock.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\musicgen\_explorers.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\models\builders.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\modules\conv.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\musicgen\musicgen_pretrained_32khz_eval.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>demos\musicgen_app.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\solvers\compression.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\models\audiogen.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\compression\encodec_base_24khz.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>tests\common_utils\temp_utils.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\musicgen\musicgen_melody_32khz.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\musicgen\musicgen_clapemb_32khz.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\solvers\builders.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\optim\cosine_lr_scheduler.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\musicgen\musicgen_base_cached_32khz.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\compression\encodec_musicgen_32khz.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\models\encodec.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\diffusion\_explorers.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\modules\codebooks_patterns.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\solvers\musicgen.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\solvers\diffusion.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\audiogen\audiogen_base_16khz.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\audiogen\audiogen_pretrained_16khz_eval.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\_base_explorers.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>tests\modules\test_codebooks_patterns.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\compression\encodec_audiogen_16khz.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\models\musicgen.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\optim\linear_warmup_lr_scheduler.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\compression\_explorers.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\optim\inverse_sqrt_lr_scheduler.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\optim\polynomial_decay_lr_scheduler.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\models\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>tests\models\test_musicgen.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>tests\models\test_multibanddiffusion.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\quantization\core_vq.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\modules\transformer.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\modules\diffusion_schedule.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>tests\models\test_encodec_model.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\models\lm.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\data\music_dataset.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\modules\conditioners.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\data\sound_dataset.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\diffusion\4_bands_base_32khz.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\compression\debug.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\utils\utils.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>tests\data\test_audio_dataset.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>tests\modules\test_transformer.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\solvers\base.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>audiocraft\grids\musicgen\musicgen_base_32khz.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><hr><h1>setup.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 64e7d6f..73fc7fb 100644<br><span style="color:blue;">@@ -60,3 +60,4 @@</span><br>         'Topic :: Scientific/Engineering :: Artificial Intelligence',<br>     ],<br> )<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 64e7d6f..73fc7fb 100644<br><span style="color:blue;">@@ -60,3 +60,4 @@</span><br>         'Topic :: Scientific/Engineering :: Artificial Intelligence',<br>     ],<br> )<br><span style="color:green;">+</span><br><hr><h1>audiocraft\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 6ab3460..9223858 100644<br><span style="color:blue;">@@ -24,3 +24,4 @@</span><br> from . import data, modules, models<br> <br> __version__ = '1.0.0'<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 6ab3460..9223858 100644<br><span style="color:blue;">@@ -24,3 +24,4 @@</span><br> from . import data, modules, models<br> <br> __version__ = '1.0.0'<br><span style="color:green;">+</span><br><hr><h1>audiocraft\train.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 22dd117..0d6d2af 100644<br><span style="color:blue;">@@ -154,4 +154,4 @@ def main(cfg):</span><br>     main.dora.shared = None<br> <br> if __name__ == '__main__':<br><span style="color:orangered;">-    main()</span><br><span style="color:green;">+    main()]</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 22dd117..0d6d2af 100644<br><span style="color:blue;">@@ -154,4 +154,4 @@ def main(cfg):</span><br>     main.dora.shared = None<br> <br> if __name__ == '__main__':<br><span style="color:orangered;">-    main()</span><br><span style="color:green;">+    main()]</span><br><hr><h1>audiocraft\losses\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index d55107b..45dfb02 100644<br><span style="color:blue;">@@ -19,3 +19,4 @@</span><br>     MelSpectrogramL1Loss,<br>     MultiScaleMelSpectrogramLoss,<br> )<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index d55107b..45dfb02 100644<br><span style="color:blue;">@@ -19,3 +19,4 @@</span><br>     MelSpectrogramL1Loss,<br>     MultiScaleMelSpectrogramLoss,<br> )<br><span style="color:green;">+</span><br><hr><h1>audiocraft\adversarial\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 8640587..dea0c2c 100644<br><span style="color:blue;">@@ -20,3 +20,4 @@</span><br>     FeatLossType,<br>     FeatureMatchingLoss<br> )<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 8640587..dea0c2c 100644<br><span style="color:blue;">@@ -20,3 +20,4 @@</span><br>     FeatLossType,<br>     FeatureMatchingLoss<br> )<br><span style="color:green;">+</span><br><hr><h1>audiocraft\data\audio_dataset.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 9d74425..89dba1a 100644<br><span style="color:blue;">@@ -585,3 +585,4 @@ def main():</span><br> <br> if __name__ == '__main__':<br>     main()<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 9d74425..89dba1a 100644<br><span style="color:blue;">@@ -585,3 +585,4 @@ def main():</span><br> <br> if __name__ == '__main__':<br>     main()<br><span style="color:green;">+</span><br><hr><h1>audiocraft\optim\dadam.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index a84402f..79b41a1 100644<br><span style="color:blue;">@@ -250,3 +250,4 @@ def step(self, closure=None):</span><br>             group['k'] = k + 1<br> <br>         return loss<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index a84402f..79b41a1 100644<br><span style="color:blue;">@@ -250,3 +250,4 @@ def step(self, closure=None):</span><br>             group['k'] = k + 1<br> <br>         return loss<br><span style="color:green;">+</span><br><hr><h1>tests\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><hr><h1>scripts\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><hr><h1>audiocraft\modules\lstm.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index c086617..012c6e3 100644<br><span style="color:blue;">@@ -23,3 +23,4 @@ def forward(self, x):</span><br>             y = y + x<br>         y = y.permute(1, 2, 0)<br>         return y<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index c086617..012c6e3 100644<br><span style="color:blue;">@@ -23,3 +23,4 @@ def forward(self, x):</span><br>             y = y + x<br>         y = y.permute(1, 2, 0)<br>         return y<br><span style="color:green;">+</span><br><hr><h1>tests\losses\test_losses.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index b6681e1..fd67f13 100644<br><span style="color:blue;">@@ -76,3 +76,4 @@ def test_stft_loss():</span><br>     loss = mrstft(t1, t2)<br> <br>     assert isinstance(loss, torch.Tensor)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index b6681e1..fd67f13 100644<br><span style="color:blue;">@@ -76,3 +76,4 @@ def test_stft_loss():</span><br>     loss = mrstft(t1, t2)<br> <br>     assert isinstance(loss, torch.Tensor)<br><span style="color:green;">+</span><br><hr><h1>tests\modules\test_lstm.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 1248964..948e79b 100644<br><span style="color:blue;">@@ -30,3 +30,4 @@ def test_lstm_skip(self):</span><br>         y = lstm(x)<br> <br>         assert y.shape == torch.Size([B, C, T])<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 1248964..948e79b 100644<br><span style="color:blue;">@@ -30,3 +30,4 @@ def test_lstm_skip(self):</span><br>         y = lstm(x)<br> <br>         assert y.shape == torch.Size([B, C, T])<br><span style="color:green;">+</span><br><hr><h1>audiocraft\data\audio.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 2ac5e6c..34104ea 100644<br><span style="color:blue;">@@ -216,3 +216,4 @@ def audio_write(stem_name: tp.Union[str, Path],</span><br>             path.unlink()<br>         raise<br>     return path<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 2ac5e6c..34104ea 100644<br><span style="color:blue;">@@ -216,3 +216,4 @@ def audio_write(stem_name: tp.Union[str, Path],</span><br>             path.unlink()<br>         raise<br>     return path<br><span style="color:green;">+</span><br><hr><h1>audiocraft\data\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 2906ff1..4914f41 100644<br><span style="color:blue;">@@ -8,3 +8,4 @@</span><br> <br> # flake8: noqa<br> from . import audio, audio_dataset, info_audio_dataset, music_dataset, sound_dataset<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 2906ff1..4914f41 100644<br><span style="color:blue;">@@ -8,3 +8,4 @@</span><br> <br> # flake8: noqa<br> from . import audio, audio_dataset, info_audio_dataset, music_dataset, sound_dataset<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\cache.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 2fccc0a..c05ff3e 100644<br><span style="color:blue;">@@ -321,3 +321,4 @@ def _get_next():</span><br>                 if batch is None:<br>                     return<br>                 yield batch<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 2fccc0a..c05ff3e 100644<br><span style="color:blue;">@@ -321,3 +321,4 @@ def _get_next():</span><br>                 if batch is None:<br>                     return<br>                 yield batch<br><span style="color:green;">+</span><br><hr><h1>tests\data\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><hr><h1>tests\utils\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><hr><h1>tests\modules\test_rope.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 067c6f0..548711e 100644<br><span style="color:blue;">@@ -166,3 +166,4 @@ def test_positional_scale():</span><br> <br>     assert torch.allclose(xq, xq_out)<br>     assert torch.allclose(xk, xk_out)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 067c6f0..548711e 100644<br><span style="color:blue;">@@ -166,3 +166,4 @@ def test_positional_scale():</span><br> <br>     assert torch.allclose(xq, xq_out)<br>     assert torch.allclose(xk, xk_out)<br><span style="color:green;">+</span><br><hr><h1>audiocraft\environment.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index adc7819..1530545 100644<br><span style="color:blue;">@@ -174,3 +174,4 @@ def apply_dataset_mappers(cls, path: str) -> str:</span><br>             path = pattern.sub(repl, path)<br> <br>         return path<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index adc7819..1530545 100644<br><span style="color:blue;">@@ -174,3 +174,4 @@ def apply_dataset_mappers(cls, path: str) -> str:</span><br>             path = pattern.sub(repl, path)<br> <br>         return path<br><span style="color:green;">+</span><br><hr><h1>tests\losses\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><hr><h1>tests\modules\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><hr><h1>audiocraft\losses\specloss.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 11f2eb3..3f1d83e 100644<br><span style="color:blue;">@@ -147,3 +147,4 @@ def forward(self, x, y):</span><br>         if self.normalized:<br>             loss = loss / self.total<br>         return loss<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 11f2eb3..3f1d83e 100644<br><span style="color:blue;">@@ -147,3 +147,4 @@ def forward(self, x, y):</span><br>         if self.normalized:<br>             loss = loss / self.total<br>         return loss<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\checkpoint.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index f6f8718..8562ad2 100644<br><span style="color:blue;">@@ -159,3 +159,4 @@ def _barrier_if_sharded():</span><br>     _barrier_if_sharded()<br>     if flashy.distrib.rank() == 0:<br>         token.unlink()<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index f6f8718..8562ad2 100644<br><span style="color:blue;">@@ -159,3 +159,4 @@ def _barrier_if_sharded():</span><br>     _barrier_if_sharded()<br>     if flashy.distrib.rank() == 0:<br>         token.unlink()<br><span style="color:green;">+</span><br><hr><h1>tests\adversarial\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><hr><h1>audiocraft\solvers\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index ae19f3a..eb0ce12 100644<br><span style="color:blue;">@@ -15,3 +15,4 @@</span><br> from .compression import CompressionSolver<br> from .musicgen import MusicGenSolver<br> from .diffusion import DiffusionSolver<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index ae19f3a..eb0ce12 100644<br><span style="color:blue;">@@ -15,3 +15,4 @@</span><br> from .compression import CompressionSolver<br> from .musicgen import MusicGenSolver<br> from .diffusion import DiffusionSolver<br><span style="color:green;">+</span><br><hr><h1>audiocraft\data\audio_utils.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 9d3129b..37e9dfe 100644<br><span style="color:blue;">@@ -174,3 +174,4 @@ def i16_pcm(wav: torch.Tensor) -> torch.Tensor:</span><br>     else:<br>         assert wav.dtype == torch.int16<br>         return wav<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 9d3129b..37e9dfe 100644<br><span style="color:blue;">@@ -174,3 +174,4 @@ def i16_pcm(wav: torch.Tensor) -> torch.Tensor:</span><br>     else:<br>         assert wav.dtype == torch.int16<br>         return wav<br><span style="color:green;">+</span><br><hr><h1>tests\common_utils\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 74ffcfe..d6a2922 100644<br><span style="color:blue;">@@ -7,3 +7,4 @@</span><br> # flake8: noqa<br> from .temp_utils import TempDirMixin<br> from .wav_utils import get_batch_white_noise, get_white_noise, save_wav<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 74ffcfe..d6a2922 100644<br><span style="color:blue;">@@ -7,3 +7,4 @@</span><br> # flake8: noqa<br> from .temp_utils import TempDirMixin<br> from .wav_utils import get_batch_white_noise, get_white_noise, save_wav<br><span style="color:green;">+</span><br><hr><h1>audiocraft\models\unet.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index db4a6df..00c02bb 100644<br><span style="color:blue;">@@ -212,3 +212,4 @@ def forward(self, x: torch.Tensor, step: tp.Union[int, torch.Tensor], condition:</span><br> <br>         z = z[:, :, :x.shape[2]]<br>         return Output(z)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index db4a6df..00c02bb 100644<br><span style="color:blue;">@@ -212,3 +212,4 @@ def forward(self, x: torch.Tensor, step: tp.Union[int, torch.Tensor], condition:</span><br> <br>         z = z[:, :, :x.shape[2]]<br>         return Output(z)<br><span style="color:green;">+</span><br><hr><h1>audiocraft\modules\activations.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 2d83d7c..c0641ba 100644<br><span style="color:blue;">@@ -94,3 +94,4 @@ def get_activation_fn(</span><br>         elif activation == "swiglu":<br>             return SwiGLU()<br>     return activation<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 2d83d7c..c0641ba 100644<br><span style="color:blue;">@@ -94,3 +94,4 @@ def get_activation_fn(</span><br>         elif activation == "swiglu":<br>             return SwiGLU()<br>     return activation<br><span style="color:green;">+</span><br><hr><h1>audiocraft\metrics\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 3474bdc..d1fc546 100644<br><span style="color:blue;">@@ -12,3 +12,4 @@</span><br> from .kld import KLDivergenceMetric, PasstKLDivergenceMetric<br> from .rvm import RelativeVolumeMel<br> from .visqol import ViSQOL<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 3474bdc..d1fc546 100644<br><span style="color:blue;">@@ -12,3 +12,4 @@</span><br> from .kld import KLDivergenceMetric, PasstKLDivergenceMetric<br> from .rvm import RelativeVolumeMel<br> from .visqol import ViSQOL<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 75e25a0..e5cc357 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """Utilities."""<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 75e25a0..e5cc357 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """Utilities."""<br><span style="color:green;">+</span><br><hr><h1>audiocraft\quantization\vq.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index aa57bea..c73b812 100644<br><span style="color:blue;">@@ -113,3 +113,4 @@ def num_codebooks(self):</span><br>     def set_num_codebooks(self, n: int):<br>         assert n > 0 and n <= self.max_n_q<br>         self.n_q = n<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index aa57bea..c73b812 100644<br><span style="color:blue;">@@ -113,3 +113,4 @@ def num_codebooks(self):</span><br>     def set_num_codebooks(self, n: int):<br>         assert n > 0 and n <= self.max_n_q<br>         self.n_q = n<br><span style="color:green;">+</span><br><hr><h1>audiocraft\grids\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 7064351..7925b59 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """Dora Grids."""<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 7064351..7925b59 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """Dora Grids."""<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\autocast.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index ed64484..6830125 100644<br><span style="color:blue;">@@ -38,3 +38,4 @@ def __exit__(self, *args, **kwargs):</span><br>         if self.autocast is None:<br>             return<br>         self.autocast.__exit__(*args, **kwargs)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index ed64484..6830125 100644<br><span style="color:blue;">@@ -38,3 +38,4 @@ def __exit__(self, *args, **kwargs):</span><br>         if self.autocast is None:<br>             return<br>         self.autocast.__exit__(*args, **kwargs)<br><span style="color:green;">+</span><br><hr><h1>audiocraft\modules\chroma.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index e84fb66..4d91af5 100644<br><span style="color:blue;">@@ -64,3 +64,4 @@ def forward(self, wav: torch.Tensor) -> torch.Tensor:</span><br>             norm_chroma.scatter_(dim=-1, index=idx, value=1)<br> <br>         return norm_chroma<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index e84fb66..4d91af5 100644<br><span style="color:blue;">@@ -64,3 +64,4 @@ def forward(self, wav: torch.Tensor) -> torch.Tensor:</span><br>             norm_chroma.scatter_(dim=-1, index=idx, value=1)<br> <br>         return norm_chroma<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\notebook.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 019b9d1..5c19b68 100644<br><span style="color:blue;">@@ -30,3 +30,4 @@ def display_audio(samples: torch.Tensor, sample_rate: int):</span><br> <br>     for audio in samples:<br>         ipd.display(ipd.Audio(audio, rate=sample_rate))<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 019b9d1..5c19b68 100644<br><span style="color:blue;">@@ -30,3 +30,4 @@ def display_audio(samples: torch.Tensor, sample_rate: int):</span><br> <br>     for audio in samples:<br>         ipd.display(ipd.Audio(audio, rate=sample_rate))<br><span style="color:green;">+</span><br><hr><h1>audiocraft\quantization\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 1e0c7e4..06b40fa 100644<br><span style="color:blue;">@@ -7,3 +7,4 @@</span><br> # flake8: noqa<br> from .vq import ResidualVectorQuantizer<br> from .base import BaseQuantizer, DummyQuantizer, QuantizedResult<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 1e0c7e4..06b40fa 100644<br><span style="color:blue;">@@ -7,3 +7,4 @@</span><br> # flake8: noqa<br> from .vq import ResidualVectorQuantizer<br> from .base import BaseQuantizer, DummyQuantizer, QuantizedResult<br><span style="color:green;">+</span><br><hr><h1>audiocraft\metrics\visqol.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 44f4b0a..1ef085e 100644<br><span style="color:blue;">@@ -214,3 +214,4 @@ def __call__(</span><br>             logger.error("Exception occurred when running ViSQOL: %s", e)<br>         finally:<br>             self._flush_files(tmp_dir)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 44f4b0a..1ef085e 100644<br><span style="color:blue;">@@ -214,3 +214,4 @@ def __call__(</span><br>             logger.error("Exception occurred when running ViSQOL: %s", e)<br>         finally:<br>             self._flush_files(tmp_dir)<br><span style="color:green;">+</span><br><hr><h1>audiocraft\modules\streaming.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index fba0693..c1b2237 100644<br><span style="color:blue;">@@ -129,3 +129,4 @@ def flush(self, x: tp.Optional[torch.Tensor] = None):</span><br>             elif x is not None:<br>                 x = module(x)<br>         return x<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index fba0693..c1b2237 100644<br><span style="color:blue;">@@ -129,3 +129,4 @@ def flush(self, x: tp.Optional[torch.Tensor] = None):</span><br>             elif x is not None:<br>                 x = module(x)<br>         return x<br><span style="color:green;">+</span><br><hr><h1>audiocraft\metrics\kld.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index ebbbcda..25f8d20 100644<br><span style="color:blue;">@@ -218,3 +218,4 @@ def _get_label_distribution(self, x: torch.Tensor, sizes: torch.Tensor,</span><br>             return torch.stack(all_probs, dim=0)<br>         else:<br>             return None<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index ebbbcda..25f8d20 100644<br><span style="color:blue;">@@ -218,3 +218,4 @@ def _get_label_distribution(self, x: torch.Tensor, sizes: torch.Tensor,</span><br>             return torch.stack(all_probs, dim=0)<br>         else:<br>             return None<br><span style="color:green;">+</span><br><hr><h1>tests\models\test_audiogen.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 3850af0..2994b9f 100644<br><span style="color:blue;">@@ -51,3 +51,4 @@ def test_generate_long(self):</span><br>         wav = ag.generate(<br>             ['youpi', 'lapin dort'])<br>         assert list(wav.shape) == [2, 1, 16000 * 4]<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 3850af0..2994b9f 100644<br><span style="color:blue;">@@ -51,3 +51,4 @@ def test_generate_long(self):</span><br>         wav = ag.generate(<br>             ['youpi', 'lapin dort'])<br>         assert list(wav.shape) == [2, 1, 16000 * 4]<br><span style="color:green;">+</span><br><hr><h1>audiocraft\data\zip.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index f0b1784..0c250e9 100644<br><span style="color:blue;">@@ -74,3 +74,4 @@ def open_file_in_zip(path_in_zip: PathInZip, mode: str = 'r') -> typing.IO:</span><br>     """<br>     zf = _cached_open_zip(path_in_zip.zip_path)<br>     return zf.open(path_in_zip.file_path)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index f0b1784..0c250e9 100644<br><span style="color:blue;">@@ -74,3 +74,4 @@ def open_file_in_zip(path_in_zip: PathInZip, mode: str = 'r') -> typing.IO:</span><br>     """<br>     zf = _cached_open_zip(path_in_zip.zip_path)<br>     return zf.open(path_in_zip.file_path)<br><span style="color:green;">+</span><br><hr><h1>audiocraft\modules\seanet.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 3e5998e..3fb0669 100644<br><span style="color:blue;">@@ -256,3 +256,4 @@ def __init__(self, channels: int = 1, dimension: int = 128, n_filters: int = 32,</span><br>     def forward(self, z):<br>         y = self.model(z)<br>         return y<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 3e5998e..3fb0669 100644<br><span style="color:blue;">@@ -256,3 +256,4 @@ def __init__(self, channels: int = 1, dimension: int = 128, n_filters: int = 32,</span><br>     def forward(self, z):<br>         y = self.model(z)<br>         return y<br><span style="color:green;">+</span><br><hr><h1>audiocraft\optim\fsdp.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index b3c1a55..8ff6b38 100644<br><span style="color:blue;">@@ -193,3 +193,4 @@ def _post_backward_hook(state, handle, *args, **kwargs):</span><br>         old_hook(state, handle, *args, **kwargs)<br> <br>     _runtime_utils._post_backward_hook = _post_backward_hook<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index b3c1a55..8ff6b38 100644<br><span style="color:blue;">@@ -193,3 +193,4 @@ def _post_backward_hook(state, handle, *args, **kwargs):</span><br>         old_hook(state, handle, *args, **kwargs)<br> <br>     _runtime_utils._post_backward_hook = _post_backward_hook<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\samples\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 0952fcc..fe3d6d0 100644<br><span style="color:blue;">@@ -3,3 +3,4 @@</span><br> #<br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br><span style="color:green;">+</span><br><hr><h1>audiocraft\adversarial\losses.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index be293e7..1673477 100644<br><span style="color:blue;">@@ -226,3 +226,4 @@ def forward(self, fmap_fake: tp.List[torch.Tensor], fmap_real: tp.List[torch.Ten</span><br>             feat_loss /= n_fmaps<br> <br>         return feat_loss<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index be293e7..1673477 100644<br><span style="color:blue;">@@ -226,3 +226,4 @@ def forward(self, fmap_fake: tp.List[torch.Tensor], fmap_real: tp.List[torch.Ten</span><br>             feat_loss /= n_fmaps<br> <br>         return feat_loss<br><span style="color:green;">+</span><br><hr><h1>audiocraft\metrics\fad.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index de66138..d034a02 100644<br><span style="color:blue;">@@ -327,3 +327,4 @@ def compute(self) -> float:</span><br>         logger.warning(f"FAD score = {fad_score}")<br>         fad_score = flashy.distrib.broadcast_object(fad_score, src=0)<br>         return fad_score<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index de66138..d034a02 100644<br><span style="color:blue;">@@ -327,3 +327,4 @@ def compute(self) -> float:</span><br>         logger.warning(f"FAD score = {fad_score}")<br>         fad_score = flashy.distrib.broadcast_object(fad_score, src=0)<br>         return fad_score<br><span style="color:green;">+</span><br><hr><h1>audiocraft\optim\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index f48c17d..67ae232 100644<br><span style="color:blue;">@@ -14,3 +14,4 @@</span><br> from .linear_warmup_lr_scheduler import LinearWarmupLRScheduler<br> from .polynomial_decay_lr_scheduler import PolynomialDecayLRScheduler<br> from .ema import ModuleDictEMA<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index f48c17d..67ae232 100644<br><span style="color:blue;">@@ -14,3 +14,4 @@</span><br> from .linear_warmup_lr_scheduler import LinearWarmupLRScheduler<br> from .polynomial_decay_lr_scheduler import PolynomialDecayLRScheduler<br> from .ema import ModuleDictEMA<br><span style="color:green;">+</span><br><hr><h1>audiocraft\modules\rope.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 503e674..bf55d88 100644<br><span style="color:blue;">@@ -119,3 +119,4 @@ def rotate_qk(self, query: torch.Tensor, key: torch.Tensor, start: int = 0):</span><br>         key_out = self.rotate(key, start, invert_decay=True)<br> <br>         return query_out, key_out<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 503e674..bf55d88 100644<br><span style="color:blue;">@@ -119,3 +119,4 @@ def rotate_qk(self, query: torch.Tensor, key: torch.Tensor, start: int = 0):</span><br>         key_out = self.rotate(key, start, invert_decay=True)<br> <br>         return query_out, key_out<br><span style="color:green;">+</span><br><hr><h1>tests\modules\test_seanet.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index e5c51b3..2a1db50 100644<br><span style="color:blue;">@@ -113,3 +113,4 @@ def test_disable_norm_raises_exception(self):</span><br> <br>         with pytest.raises(AssertionError):<br>             SEANetDecoder(ratios=[1, 1, 2, 2], disable_norm_outer_blocks=7)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index e5c51b3..2a1db50 100644<br><span style="color:blue;">@@ -113,3 +113,4 @@ def test_disable_norm_raises_exception(self):</span><br> <br>         with pytest.raises(AssertionError):<br>             SEANetDecoder(ratios=[1, 1, 2, 2], disable_norm_outer_blocks=7)<br><span style="color:green;">+</span><br><hr><h1>tests\quantization\test_vq.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index c215099..5e35ce3 100644<br><span style="color:blue;">@@ -16,3 +16,4 @@ def test_rvq(self):</span><br>         vq = ResidualVectorQuantizer(n_q=8, dimension=16, bins=8)<br>         res = vq(x, 1.)<br>         assert res.x.shape == torch.Size([1, 16, 2048])<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index c215099..5e35ce3 100644<br><span style="color:blue;">@@ -16,3 +16,4 @@ def test_rvq(self):</span><br>         vq = ResidualVectorQuantizer(n_q=8, dimension=16, bins=8)<br>         res = vq(x, 1.)<br>         assert res.x.shape == torch.Size([1, 16, 2048])<br><span style="color:green;">+</span><br><hr><h1>audiocraft\adversarial\discriminators\base.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index a9d517e..1b642b9 100644<br><span style="color:blue;">@@ -32,3 +32,4 @@ def num_discriminators(self) -> int:</span><br>         """Number of discriminators.<br>         """<br>         ...<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index a9d517e..1b642b9 100644<br><span style="color:blue;">@@ -32,3 +32,4 @@ def num_discriminators(self) -> int:</span><br>         """Number of discriminators.<br>         """<br>         ...<br><span style="color:green;">+</span><br><hr><h1>audiocraft\optim\ema.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 4337eaf..d586ae6 100644<br><span style="color:blue;">@@ -83,3 +83,4 @@ def load_state_dict(self, state):</span><br>         for module_name, module in state['state'].items():<br>             for key, val in module.items():<br>                 self.state[module_name][key].copy_(val)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 4337eaf..d586ae6 100644<br><span style="color:blue;">@@ -83,3 +83,4 @@ def load_state_dict(self, state):</span><br>         for module_name, module in state['state'].items():<br>             for key, val in module.items():<br>                 self.state[module_name][key].copy_(val)<br><span style="color:green;">+</span><br><hr><h1>scripts\resample_dataset.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index af52887..a2f86e5 100644<br><span style="color:blue;">@@ -205,3 +205,4 @@ def process_dataset(args, n_shards: int, node_index: int, task_index: tp.Optiona</span><br>         for job in jobs:<br>             print(f"Waiting on job {job.job_id}")<br>             job.results()<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index af52887..a2f86e5 100644<br><span style="color:blue;">@@ -205,3 +205,4 @@ def process_dataset(args, n_shards: int, node_index: int, task_index: tp.Optiona</span><br>         for job in jobs:<br>             print(f"Waiting on job {job.job_id}")<br>             job.results()<br><span style="color:green;">+</span><br><hr><h1>tests\modules\test_conv.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 28fbc4f..d4190e1 100644<br><span style="color:blue;">@@ -201,3 +201,4 @@ def test_streamable_convtr1d(self):</span><br>             out = sconvtr(t0)<br>             assert isinstance(out, torch.Tensor)<br>             assert list(out.shape) == [N, C_out, expected_out_length]<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 28fbc4f..d4190e1 100644<br><span style="color:blue;">@@ -201,3 +201,4 @@ def test_streamable_convtr1d(self):</span><br>             out = sconvtr(t0)<br>             assert isinstance(out, torch.Tensor)<br>             assert list(out.shape) == [N, C_out, expected_out_length]<br><span style="color:green;">+</span><br><hr><h1>audiocraft\grids\audiogen\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 8a0a268..0630659 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """AudioGen grids."""<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 8a0a268..0630659 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """AudioGen grids."""<br><span style="color:green;">+</span><br><hr><h1>audiocraft\grids\musicgen\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index d3f101f..b5212f9 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """MusicGen grids."""<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index d3f101f..b5212f9 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """MusicGen grids."""<br><span style="color:green;">+</span><br><hr><h1>audiocraft\grids\diffusion\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index e573729..f7b84ed 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """Diffusion grids."""<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index e573729..f7b84ed 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """Diffusion grids."""<br><span style="color:green;">+</span><br><hr><h1>audiocraft\losses\stftloss.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 5ad4b7d..c8d68d2 100644<br><span style="color:blue;">@@ -205,3 +205,4 @@ def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:</span><br>         mag_loss /= len(self.stft_losses)<br> <br>         return self.factor_sc * sc_loss + self.factor_mag * mag_loss<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 5ad4b7d..c8d68d2 100644<br><span style="color:blue;">@@ -205,3 +205,4 @@ def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:</span><br>         mag_loss /= len(self.stft_losses)<br> <br>         return self.factor_sc * sc_loss + self.factor_mag * mag_loss<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\export.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 28b2140..4b69f75 100644<br><span style="color:blue;">@@ -77,3 +77,4 @@ def export_lm(checkpoint_path: tp.Union[Path, str], out_file: tp.Union[Path, str</span><br>     Path(out_file).parent.mkdir(exist_ok=True, parents=True)<br>     torch.save(new_pkg, out_file)<br>     return out_file<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 28b2140..4b69f75 100644<br><span style="color:blue;">@@ -77,3 +77,4 @@ def export_lm(checkpoint_path: tp.Union[Path, str], out_file: tp.Union[Path, str</span><br>     Path(out_file).parent.mkdir(exist_ok=True, parents=True)<br>     torch.save(new_pkg, out_file)<br>     return out_file<br><span style="color:green;">+</span><br><hr><h1>tests\adversarial\test_losses.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 0e30bc3..1e86d69 100644<br><span style="color:blue;">@@ -157,3 +157,4 @@ def test_features_matching_loss_output(self):</span><br> <br>         assert loss_layer_normed([t3], [t4]).item() == 3.0<br>         assert loss_layer_normed([t3, t3], [t4, t4]).item() == 3.0<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 0e30bc3..1e86d69 100644<br><span style="color:blue;">@@ -157,3 +157,4 @@ def test_features_matching_loss_output(self):</span><br> <br>         assert loss_layer_normed([t3], [t4]).item() == 3.0<br>         assert loss_layer_normed([t3, t3], [t4, t4]).item() == 3.0<br><span style="color:green;">+</span><br><hr><h1>audiocraft\grids\compression\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 5b68852..68e38a9 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """EnCodec grids."""<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 5b68852..68e38a9 100644<br><span style="color:blue;">@@ -4,3 +4,4 @@</span><br> # This source code is licensed under the license found in the<br> # LICENSE file in the root directory of this source tree.<br> """EnCodec grids."""<br><span style="color:green;">+</span><br><hr><h1>audiocraft\solvers\audiogen.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 1568f97..5fa9cc9 100644<br><span style="color:blue;">@@ -17,3 +17,4 @@ class AudioGenSolver(musicgen.MusicGenSolver):</span><br>     More information can be found in the AudioGen model card.<br>     """<br>     DATASET_TYPE: builders.DatasetType = builders.DatasetType.SOUND<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 1568f97..5fa9cc9 100644<br><span style="color:blue;">@@ -17,3 +17,4 @@ class AudioGenSolver(musicgen.MusicGenSolver):</span><br>     More information can be found in the AudioGen model card.<br>     """<br>     DATASET_TYPE: builders.DatasetType = builders.DatasetType.SOUND<br><span style="color:green;">+</span><br><hr><h1>tests\common_utils\wav_utils.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index d3a563e..db02ab6 100644<br><span style="color:blue;">@@ -30,3 +30,4 @@ def save_wav(path: str, wav: torch.Tensor, sample_rate: int):</span><br>     elif fp.suffix == '.mp3':<br>         kwargs['compression'] = 320<br>     torchaudio.save(str(fp), wav, sample_rate, **kwargs)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index d3a563e..db02ab6 100644<br><span style="color:blue;">@@ -30,3 +30,4 @@ def save_wav(path: str, wav: torch.Tensor, sample_rate: int):</span><br>     elif fp.suffix == '.mp3':<br>         kwargs['compression'] = 320<br>     torchaudio.save(str(fp), wav, sample_rate, **kwargs)<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\profiler.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index b45b6d1..2ec0117 100644<br><span style="color:blue;">@@ -36,3 +36,4 @@ def __enter__(self):</span><br>     def __exit__(self, exc_type, exc_value, exc_tb):<br>         if self.profiler is not None:<br>             return self.profiler.__exit__(exc_type, exc_value, exc_tb)  # type: ignore<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index b45b6d1..2ec0117 100644<br><span style="color:blue;">@@ -36,3 +36,4 @@ def __enter__(self):</span><br>     def __exit__(self, exc_type, exc_value, exc_tb):<br>         if self.profiler is not None:<br>             return self.profiler.__exit__(exc_type, exc_value, exc_tb)  # type: ignore<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\best_state.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index f5ad551..573fa09 100644<br><span style="color:blue;">@@ -79,3 +79,4 @@ def load_state_dict(self, state: flashy.state.StateDict):</span><br>         for name, sub_state in state.items():<br>             for k, v in sub_state.items():<br>                 self.states[name][k].copy_(v)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index f5ad551..573fa09 100644<br><span style="color:blue;">@@ -79,3 +79,4 @@ def load_state_dict(self, state: flashy.state.StateDict):</span><br>         for name, sub_state in state.items():<br>             for k, v in sub_state.items():<br>                 self.states[name][k].copy_(v)<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\export_legacy.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 52f145f..c1a6d0f 100644<br><span style="color:blue;">@@ -54,3 +54,4 @@ def export_lm(checkpoint_path: tp.Union[Path, str], out_folder: tp.Union[Path, s</span><br>     out_file = Path(out_folder) / f'{sig}.th'<br>     torch.save(new_pkg, out_file)<br>     return out_file<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 52f145f..c1a6d0f 100644<br><span style="color:blue;">@@ -54,3 +54,4 @@ def export_lm(checkpoint_path: tp.Union[Path, str], out_folder: tp.Union[Path, s</span><br>     out_file = Path(out_folder) / f'{sig}.th'<br>     torch.save(new_pkg, out_file)<br>     return out_file<br><span style="color:green;">+</span><br><hr><h1>audiocraft\losses\sisnr.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 30f1fa1..ea553a9 100644<br><span style="color:blue;">@@ -90,3 +90,4 @@ def forward(self, out_sig: torch.Tensor, ref_sig: torch.Tensor) -> torch.Tensor:</span><br>             torch.log10(epsilon + _norm2(proj)) - torch.log10(epsilon + _norm2(noise))<br>         )<br>         return -1 * sisnr[..., 0].mean()<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 30f1fa1..ea553a9 100644<br><span style="color:blue;">@@ -90,3 +90,4 @@ def forward(self, out_sig: torch.Tensor, ref_sig: torch.Tensor) -> torch.Tensor:</span><br>             torch.log10(epsilon + _norm2(proj)) - torch.log10(epsilon + _norm2(noise))<br>         )<br>         return -1 * sisnr[..., 0].mean()<br><span style="color:green;">+</span><br><hr><h1>tests\modules\test_activations.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 24e30d4..b1a870e 100644<br><span style="color:blue;">@@ -27,3 +27,4 @@ def test_custom_glu_calculation(self):</span><br>         assert output.shape == initial_shape<br>         # ensure the gating was calculated correctly a * f(b)<br>         assert torch.all(output == -2).item()<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 24e30d4..b1a870e 100644<br><span style="color:blue;">@@ -27,3 +27,4 @@ def test_custom_glu_calculation(self):</span><br>         assert output.shape == initial_shape<br>         # ensure the gating was calculated correctly a * f(b)<br>         assert torch.all(output == -2).item()<br><span style="color:green;">+</span><br><hr><h1>audiocraft\modules\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 6141861..7c242f6 100644<br><span style="color:blue;">@@ -19,4 +19,4 @@</span><br> )<br> from .lstm import StreamableLSTM<br> from .seanet import SEANetEncoder, SEANetDecoder<br><span style="color:orangered;">-from .transformer import StreamingTransformer</span><br>\ No newline at end of file<br><span style="color:green;">+from .transformer import StreamingTransformer</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 6141861..7c242f6 100644<br><span style="color:blue;">@@ -19,4 +19,4 @@</span><br> )<br> from .lstm import StreamableLSTM<br> from .seanet import SEANetEncoder, SEANetDecoder<br><span style="color:orangered;">-from .transformer import StreamingTransformer</span><br>\ No newline at end of file<br><span style="color:green;">+from .transformer import StreamingTransformer</span><br><hr><h1>tests\data\test_audio_utils.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 0480671..d4c094d 100644<br><span style="color:blue;">@@ -108,3 +108,4 @@ def test_normalize_audio_peak(self):</span><br>         audio = 10.0 * get_batch_white_noise(b, c, int(sr * dur))<br>         norm_audio = normalize_audio(audio, strategy='peak')<br>         assert norm_audio.abs().max() <= 1<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 0480671..d4c094d 100644<br><span style="color:blue;">@@ -108,3 +108,4 @@ def test_normalize_audio_peak(self):</span><br>         audio = 10.0 * get_batch_white_noise(b, c, int(sr * dur))<br>         norm_audio = normalize_audio(audio, strategy='peak')<br>         assert norm_audio.abs().max() <= 1<br><span style="color:green;">+</span><br><hr><h1>audiocraft\adversarial\discriminators\__init__.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index f9e5ff5..1f773e9 100644<br><span style="color:blue;">@@ -8,3 +8,4 @@</span><br> from .mpd import MultiPeriodDiscriminator<br> from .msd import MultiScaleDiscriminator<br> from .msstftd import MultiScaleSTFTDiscriminator<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index f9e5ff5..1f773e9 100644<br><span style="color:blue;">@@ -8,3 +8,4 @@</span><br> from .mpd import MultiPeriodDiscriminator<br> from .msd import MultiScaleDiscriminator<br> from .msstftd import MultiScaleSTFTDiscriminator<br><span style="color:green;">+</span><br><hr><h1>audiocraft\quantization\base.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index a77fefb..657f50c 100644<br><span style="color:blue;">@@ -97,3 +97,4 @@ def num_codebooks(self):</span><br>     def set_num_codebooks(self, n: int):<br>         """Set the number of active codebooks."""<br>         raise AttributeError("Cannot override the number of codebooks for the dummy quantizer")<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index a77fefb..657f50c 100644<br><span style="color:blue;">@@ -97,3 +97,4 @@ def num_codebooks(self):</span><br>     def set_num_codebooks(self, n: int):<br>         """Set the number of active codebooks."""<br>         raise AttributeError("Cannot override the number of codebooks for the dummy quantizer")<br><span style="color:green;">+</span><br><hr><h1>audiocraft\metrics\rvm.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 2047b6c..0d7b7fc 100644<br><span style="color:blue;">@@ -108,3 +108,4 @@ def forward(self, estimate: torch.Tensor, ground_truth: torch.Tensor) -> tp.Dict</span><br>         metrics = {f'rvm_{index}': value for index, value in enumerate(aggregated)}<br>         metrics['rvm'] = losses_per_band.mean()<br>         return metrics<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 2047b6c..0d7b7fc 100644<br><span style="color:blue;">@@ -108,3 +108,4 @@ def forward(self, estimate: torch.Tensor, ground_truth: torch.Tensor) -> tp.Dict</span><br>         metrics = {f'rvm_{index}': value for index, value in enumerate(aggregated)}<br>         metrics['rvm'] = losses_per_band.mean()<br>         return metrics<br><span style="color:green;">+</span><br><hr><h1>audiocraft\adversarial\discriminators\msd.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index c4e67e2..05a1490 100644<br><span style="color:blue;">@@ -124,3 +124,4 @@ def forward(self, x: torch.Tensor) -> MultiDiscriminatorOutputType:</span><br>             logits.append(logit)<br>             fmaps.append(fmap)<br>         return logits, fmaps<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index c4e67e2..05a1490 100644<br><span style="color:blue;">@@ -124,3 +124,4 @@ def forward(self, x: torch.Tensor) -> MultiDiscriminatorOutputType:</span><br>             logits.append(logit)<br>             fmaps.append(fmap)<br>         return logits, fmaps<br><span style="color:green;">+</span><br><hr><h1>audiocraft\adversarial\discriminators\mpd.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 8debd1f..158fcb4 100644<br><span style="color:blue;">@@ -104,3 +104,4 @@ def forward(self, x: torch.Tensor) -> MultiDiscriminatorOutputType:</span><br>             logits.append(logit)<br>             fmaps.append(fmap)<br>         return logits, fmaps<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 8debd1f..158fcb4 100644<br><span style="color:blue;">@@ -104,3 +104,4 @@ def forward(self, x: torch.Tensor) -> MultiDiscriminatorOutputType:</span><br>             logits.append(logit)<br>             fmaps.append(fmap)<br>         return logits, fmaps<br><span style="color:green;">+</span><br><hr><h1>tests\data\test_audio.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 40c0d5e..515b476 100644<br><span style="color:blue;">@@ -237,3 +237,4 @@ def test_audio_write_wav(self):</span><br>                     delta = (rescaled_read_wav - wav).abs().max()<br>                     assert torch.allclose(wav, rescaled_read_wav, rtol=0, atol=atol), (delta, atol)<br>             formats = ["wav"]  # faster unit tests<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 40c0d5e..515b476 100644<br><span style="color:blue;">@@ -237,3 +237,4 @@ def test_audio_write_wav(self):</span><br>                     delta = (rescaled_read_wav - wav).abs().max()<br>                     assert torch.allclose(wav, rescaled_read_wav, rtol=0, atol=atol), (delta, atol)<br>             formats = ["wav"]  # faster unit tests<br><span style="color:green;">+</span><br><hr><h1>audiocraft\adversarial\discriminators\msstftd.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 81a9100..3a2a2a5 100644<br><span style="color:blue;">@@ -132,3 +132,4 @@ def forward(self, x: torch.Tensor) -> MultiDiscriminatorOutputType:</span><br>             logits.append(logit)<br>             fmaps.append(fmap)<br>         return logits, fmaps<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 81a9100..3a2a2a5 100644<br><span style="color:blue;">@@ -132,3 +132,4 @@ def forward(self, x: torch.Tensor) -> MultiDiscriminatorOutputType:</span><br>             logits.append(logit)<br>             fmaps.append(fmap)<br>         return logits, fmaps<br><span style="color:green;">+</span><br><hr><h1>audiocraft\losses\balancer.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 8a0ac8a..aa23a82 100644<br><span style="color:blue;">@@ -134,3 +134,4 @@ def backward(self, losses: tp.Dict[str, torch.Tensor], input: torch.Tensor) -> t</span><br>         # Send the computed partial derivative with respect to the output of the model to the model.<br>         input.backward(out_grad)<br>         return effective_loss<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 8a0ac8a..aa23a82 100644<br><span style="color:blue;">@@ -134,3 +134,4 @@ def backward(self, losses: tp.Dict[str, torch.Tensor], input: torch.Tensor) -> t</span><br>         # Send the computed partial derivative with respect to the output of the model to the model.<br>         input.backward(out_grad)<br>         return effective_loss<br><span style="color:green;">+</span><br><hr><h1>audiocraft\utils\samples\manager.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index bf0fb21..abc9324 100644<br><span style="color:blue;">@@ -384,3 +384,4 @@ def get_samples_for_xps(xps: tp.List[dora.XP], **kwargs) -> tp.Dict[str, tp.List</span><br>     stable_samples = _match_stable_samples(samples_per_xp)<br>     unstable_samples = _match_unstable_samples(samples_per_xp)<br>     return dict(stable_samples, **unstable_samples)<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index bf0fb21..abc9324 100644<br><span style="color:blue;">@@ -384,3 +384,4 @@ def get_samples_for_xps(xps: tp.List[dora.XP], **kwargs) -> tp.Dict[str, tp.List</span><br>     stable_samples = _match_stable_samples(samples_per_xp)<br>     unstable_samples = _match_unstable_samples(samples_per_xp)<br>     return dict(stable_samples, **unstable_samples)<br><span style="color:green;">+</span><br><hr><h1>tests\adversarial\test_discriminators.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index fad89a0..7a56203 100644<br><span style="color:blue;">@@ -65,3 +65,4 @@ def test_msstftd_discriminator(self):</span><br>         assert len(fmaps) == len(n_ffts)<br>         assert all([logit.shape[0] == N and len(logit.shape) == 4 for logit in logits])<br>         assert all([feature.shape[0] == N for fmap in fmaps for feature in fmap])<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index fad89a0..7a56203 100644<br><span style="color:blue;">@@ -65,3 +65,4 @@ def test_msstftd_discriminator(self):</span><br>         assert len(fmaps) == len(n_ffts)<br>         assert all([logit.shape[0] == N and len(logit.shape) == 4 for logit in logits])<br>         assert all([feature.shape[0] == N for fmap in fmaps for feature in fmap])<br><span style="color:green;">+</span><br><hr><h1>audiocraft\metrics\clap_consistency.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index d2a6c61..673f922 100644<br><span style="color:blue;">@@ -82,3 +82,4 @@ def compute(self):</span><br>         """Computes the average cosine similarty across all audio/text pairs."""<br>         assert self.weight.item() > 0, "Unable to compute with total number of comparisons <= 0"  # type: ignore<br>         return (self.cosine_sum / self.weight).item()  # type: ignore<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index d2a6c61..673f922 100644<br><span style="color:blue;">@@ -82,3 +82,4 @@ def compute(self):</span><br>         """Computes the average cosine similarty across all audio/text pairs."""<br>         assert self.weight.item() > 0, "Unable to compute with total number of comparisons <= 0"  # type: ignore<br>         return (self.cosine_sum / self.weight).item()  # type: ignore<br><span style="color:green;">+</span><br><hr><h1>audiocraft\metrics\chroma_cosinesim.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2><br>No diff<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 40c2608..502a704 100644<br><span style="color:blue;">@@ -70,3 +70,4 @@ def compute(self) -> float:</span><br>         """Computes the average cosine similarty across all generated/target chromagrams pairs."""<br>         assert self.weight.item() > 0, "Unable to compute with total number of comparisons <= 0"  # type: ignore<br>         return (self.cosine_sum / self.weight).item()  # type: ignore<br><span style="color:green;">+</span><br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 40c2608..502a704 100644<br><span style="color:blue;">@@ -70,3 +70,4 @@ def compute(self) -> float:</span><br>         """Computes the average cosine similarty across all generated/target chromagrams pairs."""<br>         assert self.weight.item() > 0, "Unable to compute with total number of comparisons <= 0"  # type: ignore<br>         return (self.cosine_sum / self.weight).item()  # type: ignore<br><span style="color:green;">+</span><br><hr><h1>audiocraft\models\loaders.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2>index 9c7808a..7fd49d8 100644<br><span style="color:blue;">@@ -115,12 +115,17 @@ def load_lm_model(file_or_url_or_id: tp.Union[Path, str], device='cpu', cache_di</span><br>     return model<br> <br> <br><span style="color:orangered;">-def load_mbd_ckpt(file_or_url_or_id: tp.Union[Path, str], cache_dir: tp.Optional[str] = None):</span><br><span style="color:orangered;">-    return _get_state_dict(file_or_url_or_id, filename="all_in_one.pt", cache_dir=cache_dir)</span><br><span style="color:green;">+def load_mbd_ckpt(file_or_url_or_id: tp.Union[Path, str],</span><br><span style="color:green;">+                  filename: tp.Optional[str] = None,</span><br><span style="color:green;">+                  cache_dir: tp.Optional[str] = None):</span><br><span style="color:green;">+    return _get_state_dict(file_or_url_or_id, filename=filename, cache_dir=cache_dir)</span><br> <br> <br><span style="color:orangered;">-def load_diffusion_models(file_or_url_or_id: tp.Union[Path, str], device='cpu', cache_dir: tp.Optional[str] = None):</span><br><span style="color:orangered;">-    pkg = load_mbd_ckpt(file_or_url_or_id, cache_dir=cache_dir)</span><br><span style="color:green;">+def load_diffusion_models(file_or_url_or_id: tp.Union[Path, str],</span><br><span style="color:green;">+                          device='cpu',</span><br><span style="color:green;">+                          filename: tp.Optional[str] = None,</span><br><span style="color:green;">+                          cache_dir: tp.Optional[str] = None):</span><br><span style="color:green;">+    pkg = load_mbd_ckpt(file_or_url_or_id, filename=filename, cache_dir=cache_dir)</span><br>     models = []<br>     processors = []<br>     cfgs = []<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2>index 9c7808a..a158885 100644<br><span style="color:blue;">@@ -115,8 +115,10 @@ def load_lm_model(file_or_url_or_id: tp.Union[Path, str], device='cpu', cache_di</span><br>     return model<br> <br> <br><span style="color:orangered;">-def load_mbd_ckpt(file_or_url_or_id: tp.Union[Path, str], cache_dir: tp.Optional[str] = None):</span><br><span style="color:orangered;">-    return _get_state_dict(file_or_url_or_id, filename="all_in_one.pt", cache_dir=cache_dir)</span><br><span style="color:green;">+def load_mbd_ckpt(file_or_url_or_id: tp.Union[Path, str],</span><br><span style="color:green;">+                  filename: tp.Optional[str] = None,</span><br><span style="color:green;">+                  cache_dir: tp.Optional[str] = None):</span><br><span style="color:green;">+    return _get_state_dict(file_or_url_or_id, filename=filename, cache_dir=cache_dir)</span><br> <br> <br> def load_diffusion_models(file_or_url_or_id: tp.Union[Path, str], device='cpu', cache_dir: tp.Optional[str] = None):<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index 7fd49d8..a158885 100644<br><span style="color:blue;">@@ -121,11 +121,8 @@ def load_mbd_ckpt(file_or_url_or_id: tp.Union[Path, str],</span><br>     return _get_state_dict(file_or_url_or_id, filename=filename, cache_dir=cache_dir)<br> <br> <br><span style="color:orangered;">-def load_diffusion_models(file_or_url_or_id: tp.Union[Path, str],</span><br><span style="color:orangered;">-                          device='cpu',</span><br><span style="color:orangered;">-                          filename: tp.Optional[str] = None,</span><br><span style="color:orangered;">-                          cache_dir: tp.Optional[str] = None):</span><br><span style="color:orangered;">-    pkg = load_mbd_ckpt(file_or_url_or_id, filename=filename, cache_dir=cache_dir)</span><br><span style="color:green;">+def load_diffusion_models(file_or_url_or_id: tp.Union[Path, str], device='cpu', cache_dir: tp.Optional[str] = None):</span><br><span style="color:green;">+    pkg = load_mbd_ckpt(file_or_url_or_id, cache_dir=cache_dir)</span><br>     models = []<br>     processors = []<br>     cfgs = []<br><hr><h1>audiocraft\models\multibanddiffusion.py</h1><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Target</span></h2>index 1121d2f..f312fa6 100644<br><span style="color:blue;">@@ -68,10 +68,11 @@ def get_mbd_musicgen(device=None):</span><br>         """Load our diffusion models trained for MusicGen."""<br>         if device is None:<br>             device = 'cuda' if torch.cuda.is_available() else 'cpu'<br><span style="color:orangered;">-        path = 'https://dl.fbaipublicfiles.com/encodec/Diffusion/mbd_musicgen_32khz.th'</span><br><span style="color:green;">+        path = 'facebook/multiband-diffusion'</span><br><span style="color:green;">+        filename = 'mbd_musicgen_32khz.th'</span><br>         name = 'facebook/musicgen-small'<br>         codec_model = load_compression_model(name, device=device)<br><span style="color:orangered;">-        models, processors, cfgs = load_diffusion_models(path, device=device)</span><br><span style="color:green;">+        models, processors, cfgs = load_diffusion_models(path, filename=filename, device=device)</span><br>         DPs = []<br>         for i in range(len(models)):<br>             schedule = NoiseSchedule(**cfgs[i].schedule, sample_processor=processors[i], device=device)<br><span style="color:blue;">@@ -102,8 +103,9 @@ def get_mbd_24khz(bw: float = 3.0, pretrained: bool = True,</span><br>             '//pretrained/facebook/encodec_24khz', device=device)<br>         codec_model.set_num_codebooks(n_q)<br>         codec_model = codec_model.to(device)<br><span style="color:orangered;">-        path = f'https://dl.fbaipublicfiles.com/encodec/Diffusion/mbd_comp_{n_q}.pt'</span><br><span style="color:orangered;">-        models, processors, cfgs = load_diffusion_models(path, device=device)</span><br><span style="color:green;">+        path = 'facebook/multiband-diffusion'</span><br><span style="color:green;">+        filename = f'mbd_comp_{n_q}.pt'</span><br><span style="color:green;">+        models, processors, cfgs = load_diffusion_models(path, filename=filename, device=device)</span><br>         DPs = []<br>         for i in range(len(models)):<br>             schedule = NoiseSchedule(**cfgs[i].schedule, sample_processor=processors[i], device=device)<br><h2><span style="color:orangered;">Source</span> vs <span style="color:green;">Predicted</span></h2><br>No diff<br><h2><span style="color:orangered;">Target</span> vs <span style="color:green;">Predicted</span></h2>index f312fa6..1121d2f 100644<br><span style="color:blue;">@@ -68,11 +68,10 @@ def get_mbd_musicgen(device=None):</span><br>         """Load our diffusion models trained for MusicGen."""<br>         if device is None:<br>             device = 'cuda' if torch.cuda.is_available() else 'cpu'<br><span style="color:orangered;">-        path = 'facebook/multiband-diffusion'</span><br><span style="color:orangered;">-        filename = 'mbd_musicgen_32khz.th'</span><br><span style="color:green;">+        path = 'https://dl.fbaipublicfiles.com/encodec/Diffusion/mbd_musicgen_32khz.th'</span><br>         name = 'facebook/musicgen-small'<br>         codec_model = load_compression_model(name, device=device)<br><span style="color:orangered;">-        models, processors, cfgs = load_diffusion_models(path, filename=filename, device=device)</span><br><span style="color:green;">+        models, processors, cfgs = load_diffusion_models(path, device=device)</span><br>         DPs = []<br>         for i in range(len(models)):<br>             schedule = NoiseSchedule(**cfgs[i].schedule, sample_processor=processors[i], device=device)<br><span style="color:blue;">@@ -103,9 +102,8 @@ def get_mbd_24khz(bw: float = 3.0, pretrained: bool = True,</span><br>             '//pretrained/facebook/encodec_24khz', device=device)<br>         codec_model.set_num_codebooks(n_q)<br>         codec_model = codec_model.to(device)<br><span style="color:orangered;">-        path = 'facebook/multiband-diffusion'</span><br><span style="color:orangered;">-        filename = f'mbd_comp_{n_q}.pt'</span><br><span style="color:orangered;">-        models, processors, cfgs = load_diffusion_models(path, filename=filename, device=device)</span><br><span style="color:green;">+        path = f'https://dl.fbaipublicfiles.com/encodec/Diffusion/mbd_comp_{n_q}.pt'</span><br><span style="color:green;">+        models, processors, cfgs = load_diffusion_models(path, device=device)</span><br>         DPs = []<br>         for i in range(len(models)):<br>             schedule = NoiseSchedule(**cfgs[i].schedule, sample_processor=processors[i], device=device)<br></pre></body></html>